{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing, merging, exploring and cleaning for the hazardous waste datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the datasets below: \n",
    "\n",
    "haz_waste = pd.read_excel(\"farlig_avfall.xlsx\") #This is the main dataset on waste per facility\n",
    "facility_1 = pd.read_excel(\"anlegg_adresse.xlsx\") #This is a dataset with address of each facility, exl closed ones\n",
    "facility_2 = pd.read_excel(\"anlegg_adresse_v2.xlsx\") #This is a dateset later aquired with closed facilities, to be able to complete the following merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vertical concatenate facility dateframes into one complete.\n",
    "facility_complete = pd.concat([facility_2, facility_1]).drop_duplicates().reset_index(drop=True) \n",
    "\n",
    "#Fill NaNs for columns \"Status and \"Status ansvarlig enhet\"with active for active facilties, as this column name was only included in the closed facilites dataset.\n",
    "facility_complete[[\"Status\", \"Status ansvarlig enhet\"]]=facility_complete[[\"Status\", \"Status ansvarlig enhet\"]].fillna(\"Aktiv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the waste dataset with the facility dataset\n",
    "waste_merged = pd.merge(haz_waste, facility_complete, how=\"left\", left_on=\"AnleggNummer\", right_on=\"Anleggsnr.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking number of unique values in each column.\n",
    "waste_merged.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a lineplot to see overall development of hazardous waste per year.\n",
    "sns.lineplot(data=waste_merged, x=\"År\", y=\"Total mengde\", estimator=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking waste unit to check spike in 2006-08.\n",
    "sns.scatterplot(data=waste_merged, x=\"År\", y=\"Total mengde\", hue=\"Enhet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a converter to convert kilogram and liter to ton.\n",
    "def to_ton_converter(row, amount_col, unit_col, kg_to_ton=0.001, liter_to_ton=0.0008):\n",
    "    amount = row[amount_col]\n",
    "    unit = row [unit_col]\n",
    "\n",
    "    if unit == 'Kilogram':\n",
    "        return amount * kg_to_ton\n",
    "    elif unit == 'Liter':\n",
    "        return amount * liter_to_ton\n",
    "    elif unit == 'Tonn':\n",
    "        return amount\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#Defining columns to convert and the unit_col.\n",
    "columns_to_convert = [\n",
    "    (\"På mellomlager\", \"Mellomlager i tonn\"),\n",
    "    (\"Til gjenvinning i Norge\", \"Gjenvinning Norge i tonn\"),\n",
    "    (\"Til sluttbehandling i Norge\", \"Sluttbehandling Norge i tonn\"),\n",
    "    (\"Til gjenvinning i utlandet\", \"Gjenvinning utland i tonn\"),\n",
    "    (\"Til sluttbehandling i utlandet\", \"Sluttbehandling utland i tonn\"),\n",
    "    (\"Egenbehandlet avfall, forbrenning / pyrolyse med energi-gjenvinning\", \"Egenbeh forbrenning m energi-gjenvinning i tonn\"),\n",
    "    (\"Egenbehandlet avfall, forbrenning / pyrolyse uten energi-gjenvinning\", \"Egenbeh forbrenning u energigjenvinning i tonn\"),\n",
    "    (\"Egenbehandlet avfall, eget godkjent deponi\", \"Egenbeh eget godkjent deponi i tonn\"),\n",
    "    (\"Egenbehandlet avfall, annen behandling\", \"Egenbeh annen behandling i tonn\"),\n",
    "    (\"Total mengde\", \"Tot mengde i tonn\")\n",
    "]\n",
    "\n",
    "unit_col = \"Enhet\"\n",
    "\n",
    "#Using a for loop to loop through each row or every relevant columns and applying the to_ton_coverter to it. See columns_to_convert above.\n",
    "for amount_col, result_col in columns_to_convert:\n",
    "    waste_merged[result_col] = waste_merged.apply(\n",
    "        lambda row: to_ton_converter(row, amount_col=amount_col, unit_col=unit_col), axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A lineplot showing total amount of waste per year after converting kilograms and liters to ton.\n",
    "sns.lineplot(data=waste_merged, x=\"År\", y=\"Tot mengde i tonn\", estimator=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a leaner dataframe and grouping it to fit the prescription drugs data.\n",
    "waste_groupby_kommune_and_year = waste_merged[[\"År\", \"Kommune\", \"Tot mengde i tonn\"]].groupby([\"Kommune\", \"År\"]).sum()\n",
    "waste_groupby_kommune_and_year.reset_index(inplace=True) #Resetting the index to keep the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the distribution of waste per \"Kommune\" per \"År\"\n",
    "sns.histplot(data=waste_groupby_kommune_and_year, x=\"Tot mengde i tonn\", binwidth=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing, cleaning, unstacking and merging prescription drugs datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Excel files on prescription drugs to dataframes.\n",
    "diabetes_type_II = pd.read_excel(\"diabetes_type_II.xls\", header=7)\n",
    "prescription_drugs = pd.read_excel(\"Legemiddelbrukere_ny.xls\", header=8)\n",
    "\n",
    "#Because of merged cells in the original Excel file, using ffill to fill in NaNs below with value above.\n",
    "diabetes_type_II.ffill(inplace=True)\n",
    "prescription_drugs.ffill(inplace=True)\n",
    "\n",
    "#Renaming some columns to make more sense of them and for easier merge later.\n",
    "diabetes_type_II.rename(columns={\"År\": \"År_snitt\", \"Geografi\": \"Kommune\"}, inplace=True)\n",
    "prescription_drugs.rename(columns={\"År\": \"År_snitt\", \"Geografi\": \"Kommune\"}, inplace=True)\n",
    "\n",
    "#Naming nameless columns.\n",
    "diabetes_type_II.columns.values[2] = \"Type_2-diabetes\"\n",
    "prescription_drugs.columns.values[3] = \"Per_1000\"\n",
    "\n",
    "#Unstacking the one prescription drug set, so that each prescription drug has its own column, thus making it easier to merge with the Type 2 diabetes dataset. \n",
    "prescription_drugs_unstacked = prescription_drugs.set_index([\"År_snitt\", \"Kommune\", \"Legemiddelgruppe\"])[\"Per_1000\"].unstack()\n",
    "prescription_drugs_unstacked.reset_index(inplace=True) #Reset index to keep individual columns.\n",
    "\n",
    "#Merging the main prescription drug dataset (allergy, asthma, ADHD, diabetes) with the Type 2 diabetes dataset.\n",
    "prescription_complete = pd.merge(prescription_drugs_unstacked, diabetes_type_II, how=\"inner\", on=[\"Kommune\", \"År_snitt\"])\n",
    "\n",
    "#Seperating out the last year of the three year rolling mean into a new columns that then can be merged with the waste data.\n",
    "prescription_complete[\"År\"] = prescription_complete[\"År_snitt\"].str.split(\"-\").str[1]\n",
    "prescription_complete[\"År\"] = prescription_complete[\"År\"].astype(int)\n",
    "\n",
    "#Rename some prescription drug columns for easier edibilty and handling. \n",
    "prescription_complete.rename(columns={\"Diabetesmedikamenter (A10)\": \"Diabetes\", \"Midler mot astma og KOLS (R03 unntatt R03CA)\": \"Astma_og_KOLS\", \"Allergimidler (R06A, R01AC, R01AD, R01B, S01G)\": \"Allergi\", \"ADHD-midler (C02AC02, N06BA ekskl. N06BA07)\": \"ADHD\"}, inplace=True)\n",
    "\n",
    "#Selecting the prescription drugs selected for this project into a leaner dataframe. \n",
    "prescription_to_correlate = prescription_complete[[\"År\", \"Kommune\", \"Diabetes\", \"Type_2-diabetes\", \"Astma_og_KOLS\", \"Allergi\", \"ADHD\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging waste and prescription dataframes into one, and segmenting into low waste and high waste municipalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging waste df and prescription df to make a new dataset ready to do a correlation analysis:\n",
    "waste_prescription = pd.merge(waste_groupby_kommune_and_year, prescription_to_correlate, how=\"inner\", on=[\"Kommune\", \"År\"])\n",
    "\n",
    "#Converting object type numeric values to float for prescription drug columns.\n",
    "for col in waste_prescription.columns[3:]:\n",
    "    waste_prescription[col] = pd.to_numeric(waste_prescription[col], errors=\"coerce\")\n",
    "\n",
    "#Removing rows where there is no data on prescription drugs, either because of privacy or other reasons.\n",
    "waste_prescription = waste_prescription[~waste_prescription.isin(['..']).any(axis=1)]\n",
    "waste_prescription = waste_prescription[~waste_prescription.isin([':']).any(axis=1)]\n",
    "waste_prescription = waste_prescription[~waste_prescription.isnull().any(axis=1)]\n",
    "\n",
    "#Grouping by municipality to calculate the mean, then make a list of municipalities with waste > 1000 per year.\n",
    "waste_mean_kom = waste_prescription.groupby(by=\"Kommune\")[\"Tot mengde i tonn\"].mean()\n",
    "waste_mean_kom = pd.DataFrame(waste_mean_kom.reset_index())\n",
    "above_1000_ton = waste_mean_kom.query(\"`Tot mengde i tonn`> 1000\")\n",
    "list_kom=above_1000_ton['Kommune']\n",
    "high_waste_prescription = waste_prescription.query(\"Kommune in @list_kom\") #Using the list to create a high_waste dataframe ...\n",
    "low_waste_prescription = waste_prescription.query(\"Kommune not in @list_kom\") #... and a low_waste dataframe.\n",
    "\n",
    "#Creating a label column for low waste municipalities and high waste municipalities.\n",
    "low_waste_prescription[\"label\"]=\"low\"\n",
    "high_waste_prescription[\"label\"]=\"high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirming the right datatypes for the dataframe.\n",
    "print(waste_prescription.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing number of unique municipalites in each dataset. \n",
    "print(low_waste_prescription[\"Kommune\"].nunique(), high_waste_prescription[\"Kommune\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the correlation coeefficient (Pearson's) of each municipality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing personr for correlation coefficient and p-value from scipy.\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#Defining a prescription_waste_correlator that can be applied to all prescription drug columns, and group the data by municipality. \n",
    "def prescription_waste_correlator(data, waste_col, group_col=\"Kommune\", year_col=\"År\"):\n",
    "    prescription_cols = [col for col in data.columns[3:8]] #Defining the columns to loop through.\n",
    "    results = pd.DataFrame() \n",
    "\n",
    "    for prescription_col in prescription_cols:\n",
    "        #Grouping the data by Kommune (group_col) here.\n",
    "        group_data = data[[group_col, waste_col, prescription_col]].groupby([group_col])\n",
    "        \n",
    "        #Initializing lists to add municipalites, correlation coefficients and p_values when looping.\n",
    "        list_kom = []\n",
    "        list_corr = []\n",
    "        list_p_value = []\n",
    "\n",
    "        #Calculating the correlation coefficient and p-value for each group (municipality) on waste and the different prescription columns. And appending the values to the lists defined above.\n",
    "        for name, group in group_data: \n",
    "            corr_val, p_value = pearsonr(group[waste_col], group[prescription_col])\n",
    "            list_kom.append(name)\n",
    "            list_corr.append(corr_val)\n",
    "            list_p_value.append(p_value)\n",
    "        \n",
    "        #Creating a dataframe to combine the lists.\n",
    "        prescription_results = pd.DataFrame({\n",
    "            group_col: list_kom,\n",
    "            \"Legemiddel\": prescription_col,\n",
    "            \"Korrelasjon\": list_corr,\n",
    "            \"P-value\": list_p_value\n",
    "        })\n",
    "        \n",
    "        #Concatenating for each run of the loop.\n",
    "        results = pd.concat([results, prescription_results], ignore_index=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the prescription_waste_correlator function on the high_waste_prescription dataframe. \n",
    "correlation_results = prescription_waste_correlator(high_waste_prescription, \"Tot mengde i tonn\")\n",
    "\n",
    "#Only select results with a p-value of < 0,05.\n",
    "p_value_0_05 = correlation_results.query(\"`P-value` < 0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the distribution of the correlation results.\n",
    "sns.histplot(data=correlation_results, x=\"Korrelasjon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot to show the distribution of different prescription drugs.\n",
    "ax = sns.boxplot(data=p_value_0_05, y=\"Korrelasjon\", x=\"Legemiddel\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=20) #Rotating the x axis a bit to increase legibility. \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing low waste with high waste, using the labels created earlier and concatenating back into on combinded dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating high_waste with low_waste to create a full dataset, now including low and high labels.\n",
    "combined_df = pd.concat([high_waste_prescription, low_waste_prescription])\n",
    "\n",
    "#Loopig through the prescription drug columns creating a lineplot for each, using the high/low label with the hue paramenter.\n",
    "for legemiddel in combined_df.columns[3:8]:\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    sns.lineplot(data=combined_df, x=\"År\", y=legemiddel, hue=\"label\", estimator=np.mean)\n",
    "    plt.title(legemiddel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a histograph to see the allergy distribution for high vs low waste municipalities.\n",
    "sns.histplot(data=combined_df, x=\"Allergi\", hue=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further investigation into allergy, aiming to find a relationship between waste and prescription rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=waste_prescription, y=\"Allergi\", x=\"Tot mengde i tonn\", hue=\"År\", palette=\"plasma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=waste_prescription, y=\"Allergi\", x=\"Tot mengde i tonn\", hue=\"År\", palette=\"plasma\")\n",
    "plt.xscale(\"log\") #Adding a logarithmic scale to the x axis (waste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression analysis on waste and allergy prescription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "prescription = \"Allergi\"\n",
    "correlator = pearsonr #to easily switch between pearsonr and spearmanr\n",
    "\n",
    "#Creating logarithmic colums of waste and prescription.\n",
    "waste_prescription[\"log_waste\"] = np.log10(waste_prescription[\"Tot mengde i tonn\"]+1)\n",
    "waste_prescription[\"log\"+prescription] = np.log10(waste_prescription[prescription]+1)\n",
    "\n",
    "\n",
    "g = sns.lmplot(data=waste_prescription, y=\"log\"+prescription, x=\"log_waste\")\n",
    "\n",
    "#Function to calculate the correlation of the whole dataset, using logarithmic scale, and to annotate the corr_value and p_value to the plot.\n",
    "def annotate(data, **kws):\n",
    "    r, p = correlator(data[\"log\"+prescription], data['log_waste'])\n",
    "    ax = plt.gca()\n",
    "    ax.text(.8, .05, \"r={:.2f}, p={:.2g}\".format(r, p),\n",
    "            transform=ax.transAxes)\n",
    "g.map_dataframe(annotate)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding hue=\"År\" to the lineplot to visualize regression per year.\n",
    "sns.lmplot(data=waste_prescription, y=\"log\"+prescription, x=\"log_waste\", hue=\"År\", palette=\"plasma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a for loop to calculate correlation and p-value for each year and storing the results in a results dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get unique years\n",
    "years = waste_prescription[\"År\"].unique()\n",
    "\n",
    "#Dictionary to store results\n",
    "results = {\"year\": [], \"corr\": [], \"p_value\": []}\n",
    "\n",
    "#Loop through each year\n",
    "for year in years:\n",
    "    #Filter data for the current year\n",
    "    waste_prescription_years = waste_prescription[waste_prescription[\"År\"] == year]\n",
    "    \n",
    "    #Calculate the correlation (Pearson's or Spearman's depending on input above) and p-value\n",
    "    corr, p_value = correlator(waste_prescription_years[\"Allergi\"], waste_prescription_years[\"log_waste\"])\n",
    "    \n",
    "    #Store the results\n",
    "    results[\"year\"].append(year)\n",
    "    results[\"corr\"].append(corr)\n",
    "    results[\"p_value\"].append(p_value)\n",
    "\n",
    "#Convert results to a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "#Sorting the results by years.\n",
    "results_df.sort_values(by=\"year\", inplace=True)\n",
    "\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=results_df, x=\"year\", y=\"corr\") #a lineplot of correlation over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a 3D scatter plot with the help of Plotly and ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "plot_data = waste_prescription\n",
    "\n",
    "#Define variable names\n",
    "x_column = \"log_waste\"\n",
    "y_column = \"År\"\n",
    "z_column = \"logAllergi\"\n",
    "\n",
    "#Prepare the features and target arrays\n",
    "X = plot_data[[x_column, y_column]]\n",
    "y = plot_data[z_column]\n",
    "\n",
    "#Fit the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Create an array for predictions\n",
    "X_pred = pd.DataFrame({\n",
    "    x_column: np.linspace(X[x_column].min(), X[x_column].max(), 100),\n",
    "    y_column: np.linspace(X[y_column].min(), X[y_column].max(), 100)\n",
    "})\n",
    "y_pred = model.predict(X_pred)\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter plot\n",
    "fig.add_trace(go.Scatter3d(x=plot_data[x_column], y=plot_data[y_column], z=plot_data[z_column],\n",
    "                           mode='markers', marker=dict(size=2, color='blue',)),)\n",
    "\n",
    "# Add line plot\n",
    "fig.add_trace(go.Scatter3d(x=X_pred[x_column], y=X_pred[y_column], z=y_pred,\n",
    "                           mode='lines', line=dict(color='red', width=2)))\n",
    "\n",
    "# Update plot appearance\n",
    "fig.update_layout(title='3D Regression Line Plot',\n",
    "                  scene=dict(\n",
    "                      xaxis_title=x_column,\n",
    "                      yaxis_title=y_column,\n",
    "                      zaxis_title=z_column))\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oslomet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
